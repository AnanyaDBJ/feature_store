{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d168aaf-9cee-4774-bf9c-05fb2fa7c980",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Notebook Overview"
    }
   },
   "source": [
    "# Synthetic Data Generation for Churn Prediction\n",
    "\n",
    "This notebook generates synthetic event data tables to support a **churn prediction model** using Databricks declarative feature pipelines.\n",
    "\n",
    "**Target Schema:** `ananyaroy.feature_store`\n",
    "\n",
    "**Generated Tables:**\n",
    "- `user_tenant_mapping` - Maps users to their tenants\n",
    "- `user_click_events` - Raw click/action events across products\n",
    "- `confluence_events` - Page views, dwell times, and comments\n",
    "- `jira_events` - Jira activities and reactions\n",
    "- `product_entitlements` - Product access records\n",
    "- `tenant_metrics` - Tenant-level daily aggregated metrics\n",
    "- `churn_labels` - Binary churn labels for model training\n",
    "\n",
    "**Use Case:** Predict user churn based on engagement patterns across Atlassian products (Jira, Confluence, JSM, JWM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd3eba15-f2b9-41f8-b9ae-78df54f93195",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Setup Section"
    }
   },
   "source": [
    "## Entity Relationship Diagram\n",
    "\n",
    "The following diagram shows how the synthetic data tables relate to each other for the churn prediction model:\n",
    "\n",
    "```mermaid\n",
    "erDiagram\n",
    "    USER_TENANT_MAPPING ||--o{ USER_CLICK_EVENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--o{ CONFLUENCE_EVENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--o{ JIRA_EVENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--o{ PRODUCT_ENTITLEMENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--|| CHURN_LABELS : \"has\"\n",
    "    USER_TENANT_MAPPING }o--|| TENANT_METRICS : \"belongs to\"\n",
    "    \n",
    "    USER_TENANT_MAPPING {\n",
    "        string user_id PK\n",
    "        string tenant_id FK\n",
    "    }\n",
    "    \n",
    "    USER_CLICK_EVENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp event_ts\n",
    "        string action_type\n",
    "        int duration_seconds\n",
    "        string product\n",
    "    }\n",
    "    \n",
    "    CONFLUENCE_EVENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp event_ts\n",
    "        string page_id\n",
    "        string event_type\n",
    "        int dwell_time_seconds\n",
    "        int comment_count\n",
    "    }\n",
    "    \n",
    "    JIRA_EVENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp event_ts\n",
    "        string issue_id\n",
    "        string activity_type\n",
    "        int reaction_count\n",
    "        string jira_product\n",
    "        string issue_type\n",
    "    }\n",
    "    \n",
    "    PRODUCT_ENTITLEMENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp entitled_ts\n",
    "        string product\n",
    "        boolean is_active\n",
    "        int page_visits\n",
    "    }\n",
    "    \n",
    "    TENANT_METRICS {\n",
    "        string tenant_id PK_FK\n",
    "        timestamp metric_ts\n",
    "        int key_events_count\n",
    "        int active_users_count\n",
    "        int reporting_lines_count\n",
    "        int linked_aris_count\n",
    "    }\n",
    "    \n",
    "    CHURN_LABELS {\n",
    "        string user_id PK_FK\n",
    "        string tenant_id FK\n",
    "        timestamp label_ts\n",
    "        int churned\n",
    "    }\n",
    "```\n",
    "\n",
    "**Key Relationships:**\n",
    "* **user_tenant_mapping** is the central table linking users to tenants\n",
    "* **Event tables** (user_click_events, confluence_events, jira_events) capture time-series behavioral data\n",
    "* **product_entitlements** tracks product access and usage\n",
    "* **tenant_metrics** provides organizational-level context\n",
    "* **churn_labels** contains the target variable for model training\n",
    "\n",
    "**Join Keys:**\n",
    "* `user_id` - Primary key for user-level joins\n",
    "* `tenant_id` - Foreign key for tenant-level aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d362473-4ec2-4f62-87ec-cf5e09698745",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Initializes configuration parameters and creates the target catalog and schema for storing synthetic data.\n",
    "\n",
    "**Configuration:**\n",
    "- **Catalog:** `ananyaroy` - Unity Catalog namespace\n",
    "- **Schema:** `feature_store` - Schema for all feature tables\n",
    "- **Users:** 1,000 synthetic users\n",
    "- **Tenants:** 50 organizations\n",
    "- **Time Range:** 90 days of historical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f275254-9a75-428e-88d3-e32920d9241d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Initialize Configuration\n",
    "\n",
    "This cell imports required libraries and sets up configuration parameters:\n",
    "- Creates the catalog and schema if they don't exist\n",
    "- Defines the number of synthetic users and tenants\n",
    "- Sets the time window for generating historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e79c7b6-8576-463c-b2e5-d1a59c75fa1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "CATALOG = \"ananyaroy\"\n",
    "SCHEMA = \"feature_store\"\n",
    "NUM_USERS = 1000\n",
    "NUM_TENANTS = 50\n",
    "DAYS_OF_DATA = 90\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b5c7abc-e247-470e-a097-f609d1ce6021",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Helper Functions Section"
    }
   },
   "source": [
    "## Helper Functions\n",
    "\n",
    "Defines utility functions for generating synthetic data:\n",
    "- **generate_timestamps()** - Creates random timestamps within a specified date range\n",
    "- **user_tenant_data** - Generates the foundational user-to-tenant mapping that will be used across all event tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "147dd6fa-fc45-4846-ac82-f2c47aa2d540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_timestamps(num_records, days_back):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=days_back)\n",
    "    return [start_date + timedelta(seconds=random.randint(0, int((end_date - start_date).total_seconds()))) for _ in range(num_records)]\n",
    "\n",
    "# Generate user-tenant mapping\n",
    "user_tenant_data = [(f\"user_{i}\", f\"tenant_{random.randint(1, NUM_TENANTS)}\") for i in range(1, NUM_USERS + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95986dd4-71e3-49fe-bc88-e89a605a7d09",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "User-Tenant Mapping Section"
    }
   },
   "source": [
    "## 1. User-Tenant Mapping\n",
    "\n",
    "**Purpose:** Creates the foundational mapping between users and tenants.\n",
    "\n",
    "**Schema:**\n",
    "- `user_id` (String): Unique user identifier\n",
    "- `tenant_id` (String): Tenant the user belongs to\n",
    "\n",
    "**Churn Relevance:** This table establishes the user-tenant relationship, which is essential for aggregating tenant-level features and understanding organizational context in churn prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bc9e526-0123-48f1-8d27-1179ba3781c6",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770160643151}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([StructField(\"user_id\", StringType()), StructField(\"tenant_id\", StringType())])\n",
    "df = spark.createDataFrame(user_tenant_data, schema=schema)\n",
    "df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.user_tenant_mapping\")\n",
    "print(f\"Created user_tenant_mapping: {df.count()} records\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faf0f4b1-edcc-4a27-a665-2e634fe57b37",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "User Click Events Section"
    }
   },
   "source": [
    "## 2. User Click Events\n",
    "\n",
    "**Purpose:** Captures raw user interaction events across different products.\n",
    "\n",
    "**Schema:**\n",
    "- `user_id` (String): User performing the action\n",
    "- `tenant_id` (String): Associated tenant\n",
    "- `event_ts` (Timestamp): When the event occurred\n",
    "- `action_type` (String): Type of action (click, scroll, submit, navigate)\n",
    "- `duration_seconds` (Integer): Duration of the action\n",
    "- `product` (String): Product where action occurred (jira, confluence, jsm, jwm)\n",
    "\n",
    "**Features Generated:**\n",
    "- Click count per user\n",
    "- Action counts by type\n",
    "- Cross-product visit patterns\n",
    "\n",
    "**Churn Relevance:** Low engagement (fewer clicks, shorter durations) often signals disengagement and potential churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5ed8385-c9bb-4784-a86a-5f73292d970b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for user_id, tenant_id in user_tenant_data:\n",
    "    for ts in generate_timestamps(random.randint(10, 200), DAYS_OF_DATA):\n",
    "        data.append((user_id, tenant_id, ts, \n",
    "                     random.choice([\"click\", \"scroll\", \"submit\", \"navigate\"]),\n",
    "                     random.randint(1, 30),\n",
    "                     random.choice([\"jira\", \"confluence\", \"jsm\", \"jwm\"])))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", StringType()),\n",
    "    StructField(\"tenant_id\", StringType()),\n",
    "    StructField(\"event_ts\", TimestampType()),\n",
    "    StructField(\"action_type\", StringType()),\n",
    "    StructField(\"duration_seconds\", IntegerType()),\n",
    "    StructField(\"product\", StringType())\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.user_click_events\")\n",
    "print(f\"Created user_click_events: {df.count()} records\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b49a19f-6b54-4046-acc5-253e4fdc6531",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Confluence Events Section"
    }
   },
   "source": [
    "## 3. Confluence Events\n",
    "\n",
    "**Purpose:** Tracks Confluence-specific user activities including page views, dwell time, and collaboration.\n",
    "\n",
    "**Schema:**\n",
    "- `user_id` (String): User performing the activity\n",
    "- `tenant_id` (String): Associated tenant\n",
    "- `event_ts` (Timestamp): Event timestamp\n",
    "- `page_id` (String): Confluence page identifier\n",
    "- `event_type` (String): Type of event (view, dwell, comment, edit, link)\n",
    "- `dwell_time_seconds` (Integer): Time spent on page\n",
    "- `comment_count` (Integer): Number of comments made\n",
    "\n",
    "**Features Generated:**\n",
    "- User dwell time (confrelevance_user_dwelled)\n",
    "- Page view counts (confrelevance_user_viewed)\n",
    "- Comment activity (conf_content_page_comments)\n",
    "\n",
    "**Churn Relevance:** Declining Confluence engagement (fewer views, less dwell time, no comments) indicates reduced collaboration and higher churn risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8c4e2fd-d456-4c32-bdae-6afa961eb22b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for user_id, tenant_id in user_tenant_data:\n",
    "    for ts in generate_timestamps(random.randint(5, 100), DAYS_OF_DATA):\n",
    "        data.append((user_id, tenant_id, ts,\n",
    "                     f\"page_{random.randint(1, 500)}\",\n",
    "                     random.choice([\"view\", \"dwell\", \"comment\", \"edit\", \"link\"]),\n",
    "                     random.randint(5, 600),\n",
    "                     random.randint(0, 10)))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", StringType()),\n",
    "    StructField(\"tenant_id\", StringType()),\n",
    "    StructField(\"event_ts\", TimestampType()),\n",
    "    StructField(\"page_id\", StringType()),\n",
    "    StructField(\"event_type\", StringType()),\n",
    "    StructField(\"dwell_time_seconds\", IntegerType()),\n",
    "    StructField(\"comment_count\", IntegerType())\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.confluence_events\")\n",
    "print(f\"Created confluence_events: {df.count()} records\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6328afbf-ec5b-4850-89fa-c72418851f53",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Jira Events Section"
    }
   },
   "source": [
    "## 4. Jira Events\n",
    "\n",
    "**Purpose:** Captures Jira-specific activities including issue management and reactions.\n",
    "\n",
    "**Schema:**\n",
    "- `user_id` (String): User performing the activity\n",
    "- `tenant_id` (String): Associated tenant\n",
    "- `event_ts` (Timestamp): Event timestamp\n",
    "- `issue_id` (String): Jira issue identifier\n",
    "- `activity_type` (String): Type of activity (create, update, comment, transition, resolve)\n",
    "- `reaction_count` (Integer): Number of reactions received\n",
    "- `jira_product` (String): Specific Jira product (jsw, jsm, jwm)\n",
    "- `issue_type` (String): Type of issue (bug, story, task, epic)\n",
    "\n",
    "**Features Generated:**\n",
    "- Product Discovery activity (jira_productDiscovery_activity)\n",
    "- Maximum reaction counts (max_reaction_count)\n",
    "- Operational key events (jsw_afj_operational_key_events)\n",
    "\n",
    "**Churn Relevance:** Reduced Jira activity (fewer issues created/updated, no reactions) signals disengagement from core project management workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42cf3d3e-2990-46aa-9427-0805c02b0735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for user_id, tenant_id in user_tenant_data:\n",
    "    for ts in generate_timestamps(random.randint(5, 150), DAYS_OF_DATA):\n",
    "        data.append((user_id, tenant_id, ts,\n",
    "                     f\"issue_{random.randint(1, 1000)}\",\n",
    "                     random.choice([\"create\", \"update\", \"comment\", \"transition\", \"resolve\"]),\n",
    "                     random.randint(0, 20),\n",
    "                     random.choice([\"jsw\", \"jsm\", \"jwm\"]),\n",
    "                     random.choice([\"bug\", \"story\", \"task\", \"epic\"])))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", StringType()),\n",
    "    StructField(\"tenant_id\", StringType()),\n",
    "    StructField(\"event_ts\", TimestampType()),\n",
    "    StructField(\"issue_id\", StringType()),\n",
    "    StructField(\"activity_type\", StringType()),\n",
    "    StructField(\"reaction_count\", IntegerType()),\n",
    "    StructField(\"jira_product\", StringType()),\n",
    "    StructField(\"issue_type\", StringType())\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.jira_events\")\n",
    "print(f\"Created jira_events: {df.count()} records\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01248fb1-a66e-4fe8-91ca-28551417c41b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Product Entitlements Section"
    }
   },
   "source": [
    "## 5. Product Entitlements\n",
    "\n",
    "**Purpose:** Tracks which products users have access to and their usage patterns.\n",
    "\n",
    "**Schema:**\n",
    "- `user_id` (String): User with entitlement\n",
    "- `tenant_id` (String): Associated tenant\n",
    "- `entitled_ts` (Timestamp): When entitlement was granted\n",
    "- `product` (String): Product name (jira, confluence, jsm, jwm, cac_page, product_discovery)\n",
    "- `is_active` (Boolean): Whether entitlement is currently active\n",
    "- `page_visits` (Integer): Number of visits to product pages\n",
    "\n",
    "**Features Generated:**\n",
    "- CAC Page entitlement (Product_entitlement_CACPage)\n",
    "- Setup experience entitlement (jira_entitlement_setupExperience)\n",
    "\n",
    "**Churn Relevance:** Inactive entitlements or low page visits despite having access indicates lack of product adoption, a strong churn predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e29de0a-0dca-4d89-8333-df6766fd2430",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "products = [\"jira\", \"confluence\", \"jsm\", \"jwm\", \"cac_page\", \"product_discovery\"]\n",
    "data = []\n",
    "for user_id, tenant_id in user_tenant_data:\n",
    "    for product in random.sample(products, random.randint(1, len(products))):\n",
    "        ts = datetime.now() - timedelta(days=random.randint(30, DAYS_OF_DATA))\n",
    "        data.append((user_id, tenant_id, ts, product,\n",
    "                     random.choice([True, True, True, False]),\n",
    "                     random.randint(0, 100)))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", StringType()),\n",
    "    StructField(\"tenant_id\", StringType()),\n",
    "    StructField(\"entitled_ts\", TimestampType()),\n",
    "    StructField(\"product\", StringType()),\n",
    "    StructField(\"is_active\", BooleanType()),\n",
    "    StructField(\"page_visits\", IntegerType())\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.product_entitlements\")\n",
    "print(f\"Created product_entitlements: {df.count()} records\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e690292-10eb-49a6-82fb-622963fd563f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Tenant Metrics Section"
    }
   },
   "source": [
    "## 6. Tenant Metrics\n",
    "\n",
    "**Purpose:** Aggregates daily tenant-level metrics to capture organizational health signals.\n",
    "\n",
    "**Schema:**\n",
    "- `tenant_id` (String): Tenant identifier\n",
    "- `metric_ts` (Timestamp): Date of metrics\n",
    "- `key_events_count` (Integer): Count of important events\n",
    "- `active_users_count` (Integer): Number of active users\n",
    "- `reporting_lines_count` (Integer): Organizational structure metric\n",
    "- `linked_aris_count` (Integer): Count of linked artifacts\n",
    "\n",
    "**Features Generated:**\n",
    "- Tenant-level operational key events (jsw_afj_operational_key_events_tenant_counts)\n",
    "- Reporting lines (cg_reporting_lines)\n",
    "- Linked artifacts (confluence_linked_aris)\n",
    "\n",
    "**Churn Relevance:** Declining tenant-level metrics (fewer active users, reduced key events) indicate organizational disengagement and higher churn probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e12c6d1-fc26-418c-ad71-70acc0fa839e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for tenant_num in range(1, NUM_TENANTS + 1):\n",
    "    tenant_id = f\"tenant_{tenant_num}\"\n",
    "    base_date = datetime.now() - timedelta(days=DAYS_OF_DATA)\n",
    "    for day in range(DAYS_OF_DATA):\n",
    "        ts = base_date + timedelta(days=day)\n",
    "        data.append((tenant_id, ts,\n",
    "                     random.randint(10, 500),\n",
    "                     random.randint(5, 200),\n",
    "                     random.randint(0, 50),\n",
    "                     random.randint(100, 5000)))\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"tenant_id\", StringType()),\n",
    "    StructField(\"metric_ts\", TimestampType()),\n",
    "    StructField(\"key_events_count\", IntegerType()),\n",
    "    StructField(\"active_users_count\", IntegerType()),\n",
    "    StructField(\"reporting_lines_count\", IntegerType()),\n",
    "    StructField(\"linked_aris_count\", IntegerType())\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.tenant_metrics\")\n",
    "print(f\"Created tenant_metrics: {df.count()} records\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09c98b26-2ba1-4a00-b012-ddb67c74d812",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Churn Labels Section"
    }
   },
   "source": [
    "## 7. Churn Labels\n",
    "\n",
    "**Purpose:** Generates binary churn labels for supervised learning.\n",
    "\n",
    "**Schema:**\n",
    "- `user_id` (String): User identifier\n",
    "- `tenant_id` (String): Associated tenant\n",
    "- `label_ts` (Timestamp): Observation date for the label\n",
    "- `churned` (Integer): Binary label (1 = churned, 0 = retained)\n",
    "\n",
    "**Churn Relevance:** This is the target variable for the churn prediction model. Approximately 15% of users are labeled as churned to simulate realistic class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c481a456-4490-451f-8505-c5ea4c88c63c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "observation_date = datetime.now()\n",
    "data = [(user_id, tenant_id, observation_date, 1 if random.random() < 0.15 else 0) \n",
    "        for user_id, tenant_id in user_tenant_data]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", StringType()),\n",
    "    StructField(\"tenant_id\", StringType()),\n",
    "    StructField(\"label_ts\", TimestampType()),\n",
    "    StructField(\"churned\", IntegerType())\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)\n",
    "df.write.mode(\"overwrite\").saveAsTable(f\"{CATALOG}.{SCHEMA}.churn_labels\")\n",
    "print(f\"Created churn_labels: {df.count()} records\")\n",
    "print(f\"Churn rate: {df.filter(col('churned') == 1).count() / df.count():.2%}\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e9cfee3-399f-4b74-8ebb-004cbc68ce9d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verify Tables Section"
    }
   },
   "source": [
    "## Verify Tables\n",
    "\n",
    "Lists all created tables in the target schema to confirm successful data generation.\n",
    "\n",
    "All tables should be present in the `ananyaroy.feature_store` schema and ready for use in the feature engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcb13a02-5a2b-43ba-b37d-5dce13f0ba71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.sql(f\"SHOW TABLES IN {CATALOG}.{SCHEMA}\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "dbe_0c235d96-4bc7-4fb5-b118-17fd1dad0124",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "00_synthetic_data_generation",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
