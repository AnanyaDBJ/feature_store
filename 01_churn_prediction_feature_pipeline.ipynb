{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "147a1f68-408e-4549-aac9-705d0c9c4861",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1"
    }
   },
   "source": [
    "%md\n",
    "## Entity Relationship Diagram\n",
    "\n",
    "The following diagram shows how the synthetic data tables relate to each other for the churn prediction model:\n",
    "\n",
    "```mermaid\n",
    "erDiagram\n",
    "    USER_TENANT_MAPPING ||--o{ USER_CLICK_EVENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--o{ CONFLUENCE_EVENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--o{ JIRA_EVENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--o{ PRODUCT_ENTITLEMENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--|| CHURN_LABELS : \"has\"\n",
    "    USER_TENANT_MAPPING }o--|| TENANT_METRICS : \"belongs to\"\n",
    "    \n",
    "    USER_TENANT_MAPPING {\n",
    "        string user_id PK\n",
    "        string tenant_id FK\n",
    "    }\n",
    "    \n",
    "    USER_CLICK_EVENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp event_ts\n",
    "        string action_type\n",
    "        int duration_seconds\n",
    "        string product\n",
    "    }\n",
    "    \n",
    "    CONFLUENCE_EVENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp event_ts\n",
    "        string page_id\n",
    "        string event_type\n",
    "        int dwell_time_seconds\n",
    "        int comment_count\n",
    "    }\n",
    "    \n",
    "    JIRA_EVENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp event_ts\n",
    "        string issue_id\n",
    "        string activity_type\n",
    "        int reaction_count\n",
    "        string jira_product\n",
    "        string issue_type\n",
    "    }\n",
    "    \n",
    "    PRODUCT_ENTITLEMENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp entitled_ts\n",
    "        string product\n",
    "        boolean is_active\n",
    "        int page_visits\n",
    "    }\n",
    "    \n",
    "    TENANT_METRICS {\n",
    "        string tenant_id PK_FK\n",
    "        timestamp metric_ts\n",
    "        int key_events_count\n",
    "        int active_users_count\n",
    "        int reporting_lines_count\n",
    "        int linked_aris_count\n",
    "    }\n",
    "    \n",
    "    CHURN_LABELS {\n",
    "        string user_id PK_FK\n",
    "        string tenant_id FK\n",
    "        timestamp label_ts\n",
    "        int churned\n",
    "    }\n",
    "```\n",
    "\n",
    "**Key Relationships:**\n",
    "* **user_tenant_mapping** is the central table linking users to tenants\n",
    "* **Event tables** (user_click_events, confluence_events, jira_events) capture time-series behavioral data\n",
    "* **product_entitlements** tracks product access and usage\n",
    "* **tenant_metrics** provides organizational-level context\n",
    "* **churn_labels** contains the target variable for model training\n",
    "\n",
    "**Join Keys:**\n",
    "* `user_id` - Primary key for user-level joins\n",
    "* `tenant_id` - Foreign key for tenant-level aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bed8187b-1529-444b-be31-4c768b11389f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Entity Relationship Diagram\n",
    "\n",
    "The following diagram shows how the synthetic data tables relate to each other for the churn prediction model:\n",
    "\n",
    "```mermaid\n",
    "erDiagram\n",
    "    USER_TENANT_MAPPING ||--o{ USER_CLICK_EVENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--o{ CONFLUENCE_EVENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--o{ JIRA_EVENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--o{ PRODUCT_ENTITLEMENTS : \"has\"\n",
    "    USER_TENANT_MAPPING ||--|| CHURN_LABELS : \"has\"\n",
    "    USER_TENANT_MAPPING }o--|| TENANT_METRICS : \"belongs to\"\n",
    "    \n",
    "    USER_TENANT_MAPPING {\n",
    "        string user_id PK\n",
    "        string tenant_id FK\n",
    "    }\n",
    "    \n",
    "    USER_CLICK_EVENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp event_ts\n",
    "        string action_type\n",
    "        int duration_seconds\n",
    "        string product\n",
    "    }\n",
    "    \n",
    "    CONFLUENCE_EVENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp event_ts\n",
    "        string page_id\n",
    "        string event_type\n",
    "        int dwell_time_seconds\n",
    "        int comment_count\n",
    "    }\n",
    "    \n",
    "    JIRA_EVENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp event_ts\n",
    "        string issue_id\n",
    "        string activity_type\n",
    "        int reaction_count\n",
    "        string jira_product\n",
    "        string issue_type\n",
    "    }\n",
    "    \n",
    "    PRODUCT_ENTITLEMENTS {\n",
    "        string user_id FK\n",
    "        string tenant_id FK\n",
    "        timestamp entitled_ts\n",
    "        string product\n",
    "        boolean is_active\n",
    "        int page_visits\n",
    "    }\n",
    "    \n",
    "    TENANT_METRICS {\n",
    "        string tenant_id PK_FK\n",
    "        timestamp metric_ts\n",
    "        int key_events_count\n",
    "        int active_users_count\n",
    "        int reporting_lines_count\n",
    "        int linked_aris_count\n",
    "    }\n",
    "    \n",
    "    CHURN_LABELS {\n",
    "        string user_id PK_FK\n",
    "        string tenant_id FK\n",
    "        timestamp label_ts\n",
    "        int churned\n",
    "    }\n",
    "```\n",
    "\n",
    "**Key Relationships:**\n",
    "* **user_tenant_mapping** is the central table linking users to tenants\n",
    "* **Event tables** (user_click_events, confluence_events, jira_events) capture time-series behavioral data\n",
    "* **product_entitlements** tracks product access and usage\n",
    "* **tenant_metrics** provides organizational-level context\n",
    "* **churn_labels** contains the target variable for model training\n",
    "\n",
    "**Join Keys:**\n",
    "* `user_id` - Primary key for user-level joins\n",
    "* `tenant_id` - Foreign key for tenant-level aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21c0fec7-267f-46b7-a9ab-e70484a5b3c1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 2"
    }
   },
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "### Configuration Widgets\n",
    "\n",
    "This notebook uses **widgets** (query parameters) to make the catalog and schema configurable:\n",
    "- **Catalog Name**: Unity Catalog catalog where features and models will be stored\n",
    "- **Schema Name**: Schema within the catalog for organizing feature tables\n",
    "\n",
    "You can modify these values using the widgets at the top of the notebook without changing the code.\n",
    "\n",
    "### Required Libraries\n",
    "\n",
    "We'll install the latest pre-release version of `databricks-feature-engineering` which includes:\n",
    "- Declarative feature engineering APIs\n",
    "- Support for multiple window types\n",
    "- Point-in-time correctness\n",
    "- Feature materialization to offline/online stores\n",
    "- Model logging with feature lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ead78db-98d2-436e-a59f-62adf337697e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --pre databricks-feature-engineering>=0.13.1a4\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "067f5a25-66de-4fbf-9e63-13502d944880",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 4"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "from databricks.feature_engineering.entities import (\n",
    "    DeltaTableSource,\n",
    "    ContinuousWindow,\n",
    "    TumblingWindow,\n",
    "    SlidingWindow,\n",
    "    Sum,\n",
    "    Avg,\n",
    "    Count,\n",
    "    Min,\n",
    "    Max,\n",
    "    StddevPop,\n",
    "    ApproxCountDistinct,\n",
    ")\n",
    "from pyspark.sql import functions as F\n",
    "import mlflow\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Configuration - Get values from widgets\n",
    "CATALOG = dbutils.widgets.get(\"catalog\")\n",
    "SCHEMA = dbutils.widgets.get(\"schema\")\n",
    "SOURCE_SCHEMA = dbutils.widgets.get(\"source_schema\")\n",
    "# Initialize Feature Engineering Client\n",
    "fe = FeatureEngineeringClient()\n",
    "\n",
    "print(f\"Feature Engineering Client initialized for {CATALOG}.{SCHEMA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a053748-87dd-45b0-b6db-87fa599c512c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08f225a7-1347-4014-8e15-1bdecc7bed8e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 5"
    }
   },
   "source": [
    "## 2. Define Data Sources\n",
    "\n",
    "### Understanding DeltaTableSource\n",
    "\n",
    "`DeltaTableSource` is a declarative way to define your source data for feature engineering. It specifies:\n",
    "\n",
    "1. **Table Location**: Catalog, schema, and table name in Unity Catalog\n",
    "2. **Entity Columns**: The key(s) that identify the entity (e.g., `user_id`, `tenant_id`)\n",
    "3. **Timeseries Column**: The timestamp column for temporal aggregations\n",
    "\n",
    "### Why Entity and Timeseries Columns Matter\n",
    "\n",
    "- **Entity Columns**: Define the granularity of your features (user-level, tenant-level, etc.)\n",
    "- **Timeseries Column**: Enables point-in-time correctness - ensures features are computed using only data available at prediction time\n",
    "\n",
    "### Our Data Sources\n",
    "\n",
    "We'll define four data sources:\n",
    "\n",
    "1. **user_click_events**: User engagement data (clicks, sessions, products)\n",
    "2. **confluence_events**: Collaboration activity (page views, comments, dwell time)\n",
    "3. **jira_events**: Project management activity (issues, reactions, activities)\n",
    "4. **tenant_metrics**: Organization-level metrics (different entity: tenant_id)\n",
    "\n",
    "Each source has its own entity key and timestamp column, allowing us to create features at different granularities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f46574ef-22a6-4725-b3c3-eb5dc466d18d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# User Click Events Source - for user engagement features\n",
    "click_events_source = DeltaTableSource(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SOURCE_SCHEMA,\n",
    "    table_name=\"user_click_events\",\n",
    "    entity_columns=[\"user_id\"],\n",
    "    timeseries_column=\"event_ts\"\n",
    ")\n",
    "\n",
    "# Confluence Events Source - for collaboration features\n",
    "confluence_events_source = DeltaTableSource(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SOURCE_SCHEMA,\n",
    "    table_name=\"confluence_events\",\n",
    "    entity_columns=[\"user_id\"],\n",
    "    timeseries_column=\"event_ts\"\n",
    ")\n",
    "\n",
    "# Jira Events Source - for project activity features\n",
    "jira_events_source = DeltaTableSource(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SOURCE_SCHEMA,\n",
    "    table_name=\"jira_events\",\n",
    "    entity_columns=[\"user_id\"],\n",
    "    timeseries_column=\"event_ts\"\n",
    ")\n",
    "\n",
    "# Tenant Metrics Source - for tenant-level features (different entity)\n",
    "tenant_metrics_source = DeltaTableSource(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SOURCE_SCHEMA,\n",
    "    table_name=\"tenant_metrics\",\n",
    "    entity_columns=[\"tenant_id\"],\n",
    "    timeseries_column=\"metric_ts\"\n",
    ")\n",
    "\n",
    "print(\"Data sources defined:\")\n",
    "print(\"  - click_events_source (entity: user_id)\")\n",
    "print(\"  - confluence_events_source (entity: user_id)\")\n",
    "print(\"  - jira_events_source (entity: user_id)\")\n",
    "print(\"  - tenant_metrics_source (entity: tenant_id)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9433e6d-6d42-4750-88a1-b4fb58a497bd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 7"
    }
   },
   "source": [
    "## 3. Create Features with Different Window Types\n",
    "\n",
    "### 3.1 User Engagement Features (SlidingWindow)\n",
    "\n",
    "#### What is SlidingWindow?\n",
    "\n",
    "`SlidingWindow` creates **overlapping rolling aggregations** that slide forward in time:\n",
    "\n",
    "- **window_duration**: How far back to look (e.g., 7 days, 30 days)\n",
    "- **slide_duration**: How often the window moves forward (e.g., 1 day)\n",
    "\n",
    "**Example**: A 7-day window with 1-day slide:\n",
    "- Day 1: Aggregates data from Day -6 to Day 1\n",
    "- Day 2: Aggregates data from Day -5 to Day 2\n",
    "- Day 3: Aggregates data from Day -4 to Day 3\n",
    "\n",
    "This creates smooth, overlapping metrics ideal for trend analysis.\n",
    "\n",
    "#### Features We'll Create\n",
    "\n",
    "1. **user_clicks_7d**: Total clicks in last 7 days (short-term engagement)\n",
    "2. **user_clicks_30d**: Total clicks in last 30 days (long-term engagement)\n",
    "3. **avg_session_duration_7d**: Average session length (engagement quality)\n",
    "4. **total_session_duration_30d**: Total time spent (engagement depth)\n",
    "5. **unique_products_visited_30d**: Product diversity (exploration behavior)\n",
    "\n",
    "#### Why These Features Matter for Churn\n",
    "\n",
    "- Declining click counts indicate disengagement\n",
    "- Shorter sessions suggest reduced interest\n",
    "- Lower product diversity shows narrowing usage patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d91de0a9-0940-4da2-8003-545ec4ccf0f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature 1: Total clicks in last 7 days (SlidingWindow + Count)\n",
    "user_clicks_7d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"user_clicks_7d\",\n",
    "    description=\"Total user click events in the last 7 days\",\n",
    "    source=click_events_source,\n",
    "    inputs=[\"action_type\"],\n",
    "    function=Count(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=7),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 2: Total clicks in last 30 days (SlidingWindow + Count)\n",
    "user_clicks_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"user_clicks_30d\",\n",
    "    description=\"Total user click events in the last 30 days\",\n",
    "    source=click_events_source,\n",
    "    inputs=[\"action_type\"],\n",
    "    function=Count(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 3: Average session duration 7 days (SlidingWindow + Avg)\n",
    "avg_duration_7d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"avg_session_duration_7d\",\n",
    "    description=\"Average session duration in seconds over last 7 days\",\n",
    "    source=click_events_source,\n",
    "    inputs=[\"duration_seconds\"],\n",
    "    function=Avg(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=7),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 4: Total session duration 30 days (SlidingWindow + Sum)\n",
    "total_duration_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"total_session_duration_30d\",\n",
    "    description=\"Total session duration in seconds over last 30 days\",\n",
    "    source=click_events_source,\n",
    "    inputs=[\"duration_seconds\"],\n",
    "    function=Sum(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 5: Unique products visited 30 days (SlidingWindow + ApproxCountDistinct)\n",
    "unique_products_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"unique_products_visited_30d\",\n",
    "    description=\"Number of distinct products visited in last 30 days\",\n",
    "    source=click_events_source,\n",
    "    inputs=[\"product\"],\n",
    "    function=ApproxCountDistinct(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"User engagement features created (SlidingWindow):\")\n",
    "print(\"  - user_clicks_7d\")\n",
    "print(\"  - user_clicks_30d\")\n",
    "print(\"  - avg_session_duration_7d\")\n",
    "print(\"  - total_session_duration_30d\")\n",
    "print(\"  - unique_products_visited_30d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b2f394a-4fd1-47c9-bfeb-84546b14ceb8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 9"
    }
   },
   "source": [
    "### 3.2 Confluence Collaboration Features (SlidingWindow)\n",
    "\n",
    "#### Collaboration as a Churn Signal\n",
    "\n",
    "Confluence activity reflects team collaboration and knowledge sharing. Declining collaboration often precedes churn:\n",
    "- Users who stop contributing to documentation may be disengaging\n",
    "- Reduced page views suggest decreased team involvement\n",
    "- Lower comment activity indicates less communication\n",
    "\n",
    "#### Features We'll Create\n",
    "\n",
    "1. **confluence_dwell_time_14d**: Total time spent on Confluence pages (14-day window)\n",
    "2. **confluence_avg_dwell_30d**: Average time per page visit (engagement depth)\n",
    "3. **confluence_comments_30d**: Total comments made (collaboration intensity)\n",
    "4. **confluence_unique_pages_30d**: Number of unique pages visited (breadth of engagement)\n",
    "5. **confluence_events_7d_lagged**: Event count with temporal comparison capability\n",
    "6. **total_dwell_with_view_30d_lagged**: Filtered aggregation (only 'view' events)\n",
    "\n",
    "#### Advanced Features\n",
    "\n",
    "- **Filter Conditions**: The last feature uses `filter_condition=\"event_type = 'view'\"` to aggregate only specific event types\n",
    "- **Lagged Windows**: Can be used to compare current vs. previous period activity\n",
    "\n",
    "#### Why SlidingWindow for Collaboration?\n",
    "\n",
    "Collaboration patterns change gradually, so overlapping windows capture smooth trends better than discrete buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc4db6bd-26cf-447b-ad64-3d3ba83389f4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 11"
    }
   },
   "outputs": [],
   "source": [
    "# Feature 6: Total dwell time 14 days (ContinuousWindow + Sum)\n",
    "conf_dwell_time_14d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"confluence_dwell_time_14d\",\n",
    "    description=\"Total Confluence dwell time in seconds over last 14 days\",\n",
    "    source=confluence_events_source,\n",
    "    inputs=[\"dwell_time_seconds\"],\n",
    "    function=Sum(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=14),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 7: Average dwell time 30 days (ContinuousWindow + Avg)\n",
    "conf_avg_dwell_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"confluence_avg_dwell_30d\",\n",
    "    description=\"Average Confluence dwell time per page over last 30 days\",\n",
    "    source=confluence_events_source,\n",
    "    inputs=[\"dwell_time_seconds\"],\n",
    "    function=Avg(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 8: Total comments 30 days (ContinuousWindow + Sum)\n",
    "conf_comments_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"confluence_comments_30d\",\n",
    "    description=\"Total Confluence comments in last 30 days\",\n",
    "    source=confluence_events_source,\n",
    "    inputs=[\"comment_count\"],\n",
    "    function=Sum(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 9: Unique pages visited 30 days (ContinuousWindow + ApproxCountDistinct)\n",
    "conf_unique_pages_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"confluence_unique_pages_30d\",\n",
    "    description=\"Number of unique Confluence pages visited in last 30 days\",\n",
    "    source=confluence_events_source,\n",
    "    inputs=[\"page_id\"],\n",
    "    function=ApproxCountDistinct(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 10: Confluence events count with offset (ContinuousWindow with offset)\n",
    "conf_events_7d_offset = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"confluence_events_7d_lagged\",\n",
    "    description=\"Confluence events 7 days with 1 day lag (for trend comparison)\",\n",
    "    source=confluence_events_source,\n",
    "    inputs=[\"event_type\"],\n",
    "    function=Count(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=7),\n",
    "        # offset=timedelta(days=-1) ,\n",
    "        slide_duration=timedelta(days=1) # 1 day lag\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 11: Confluence events count with offset (ContinuousWindow with offset)\n",
    "conf_events_view_30d_offset = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"total_dwell_with_view_30d_lagged\",\n",
    "    description=\"Confluence events 7 days with 1 day lag (for trend comparison)\",\n",
    "    source=confluence_events_source,\n",
    "    inputs=[\"dwell_time_seconds\"],\n",
    "    function=Sum(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        # offset=timedelta(days=-1) ,\n",
    "        slide_duration=timedelta(days=1) # 1 day lag\n",
    "    ),\n",
    "    filter_condition=\"event_type = 'view'\"  # Only transactions over $100\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Confluence collaboration features created (SlidingWindow Window):\")\n",
    "print(\"  - confluence_dwell_time_14d\")\n",
    "print(\"  - confluence_avg_dwell_30d\")\n",
    "print(\"  - confluence_comments_30d\")\n",
    "print(\"  - confluence_unique_pages_30d\")\n",
    "print(\"  - confluence_events_7d_lagged (with offset)\")\n",
    "print(\"  - total_dweel_with_view_30d_lagged (with offset)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a028c90-f48e-4a6c-85f6-15132de911be",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 11"
    }
   },
   "source": [
    "### 3.3 Jira Activity Features (TumblingWindow)\n",
    "\n",
    "#### What is TumblingWindow?\n",
    "\n",
    "`TumblingWindow` creates **non-overlapping, fixed-size windows**:\n",
    "\n",
    "- Each time period is independent (no overlap)\n",
    "- Ideal for periodic reporting and discrete time buckets\n",
    "- **window_duration**: Size of each window (e.g., 7 days for weekly, 30 days for monthly)\n",
    "\n",
    "**Example**: Weekly tumbling windows:\n",
    "- Week 1: Days 1-7\n",
    "- Week 2: Days 8-14\n",
    "- Week 3: Days 15-21\n",
    "\n",
    "Each week is completely separate with no overlap.\n",
    "\n",
    "#### When to Use TumblingWindow vs SlidingWindow?\n",
    "\n",
    "| Use TumblingWindow | Use SlidingWindow |\n",
    "|-------------------|-------------------|\n",
    "| Periodic reports (weekly/monthly) | Trend analysis |\n",
    "| Discrete time buckets | Smooth rolling metrics |\n",
    "| Non-overlapping aggregations | Recent activity emphasis |\n",
    "| Comparing distinct periods | Continuous monitoring |\n",
    "\n",
    "#### Features We'll Create\n",
    "\n",
    "1. **jira_activities_weekly**: Count of Jira activities per week\n",
    "2. **jira_max_reactions_weekly**: Peak engagement in each week\n",
    "3. **jira_total_reactions_monthly**: Monthly reaction totals\n",
    "4. **jira_unique_issues_monthly**: Issue diversity per month\n",
    "5. **jira_min_reactions_weekly**: Minimum engagement baseline\n",
    "\n",
    "#### Why These Features Matter\n",
    "\n",
    "- Weekly/monthly patterns reveal work rhythms\n",
    "- Max/min reactions show engagement range\n",
    "- Unique issue counts indicate project involvement breadth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "853b7ca1-a0ea-4a89-9a2b-560263d21779",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature 11: Jira activities weekly (TumblingWindow + Count)\n",
    "jira_activities_weekly = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"jira_activities_weekly\",\n",
    "    description=\"Count of Jira activities in weekly tumbling window\",\n",
    "    source=jira_events_source,\n",
    "    inputs=[\"activity_type\"],\n",
    "    function=Count(),\n",
    "    time_window=TumblingWindow(\n",
    "        window_duration=timedelta(days=7)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 12: Max reactions weekly (TumblingWindow + Max)\n",
    "jira_max_reactions_weekly = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"jira_max_reactions_weekly\",\n",
    "    description=\"Maximum reaction count on any Jira activity in weekly window\",\n",
    "    source=jira_events_source,\n",
    "    inputs=[\"reaction_count\"],\n",
    "    function=Max(),\n",
    "    time_window=TumblingWindow(\n",
    "        window_duration=timedelta(days=7)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 13: Total reactions monthly (TumblingWindow + Sum)\n",
    "jira_total_reactions_monthly = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"jira_total_reactions_monthly\",\n",
    "    description=\"Total reactions on Jira activities in monthly tumbling window\",\n",
    "    source=jira_events_source,\n",
    "    inputs=[\"reaction_count\"],\n",
    "    function=Sum(),\n",
    "    time_window=TumblingWindow(\n",
    "        window_duration=timedelta(days=30)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 14: Unique issues worked on monthly (TumblingWindow + ApproxCountDistinct)\n",
    "jira_unique_issues_monthly = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"jira_unique_issues_monthly\",\n",
    "    description=\"Number of unique Jira issues worked on in monthly window\",\n",
    "    source=jira_events_source,\n",
    "    inputs=[\"issue_id\"],\n",
    "    function=ApproxCountDistinct(),\n",
    "    time_window=TumblingWindow(\n",
    "        window_duration=timedelta(days=30)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 15: Min reactions weekly (TumblingWindow + Min)\n",
    "jira_min_reactions_weekly = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"jira_min_reactions_weekly\",\n",
    "    description=\"Minimum reaction count on Jira activities in weekly window\",\n",
    "    source=jira_events_source,\n",
    "    inputs=[\"reaction_count\"],\n",
    "    function=Min(),\n",
    "    time_window=TumblingWindow(\n",
    "        window_duration=timedelta(days=7)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Jira activity features created (TumblingWindow):\")\n",
    "print(\"  - jira_activities_weekly\")\n",
    "print(\"  - jira_max_reactions_weekly\")\n",
    "print(\"  - jira_total_reactions_monthly\")\n",
    "print(\"  - jira_unique_issues_monthly\")\n",
    "print(\"  - jira_min_reactions_weekly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2496ce5-b5b4-44ac-84ca-8f1f9ba7a452",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 13"
    }
   },
   "source": [
    "### 3.4 Jira Features with Filter Conditions\n",
    "\n",
    "#### Advanced Feature Engineering: Filter Conditions\n",
    "\n",
    "The `filter_condition` parameter allows you to create **filtered aggregations** without pre-filtering your source data:\n",
    "\n",
    "**Benefits**:\n",
    "1. **Reusability**: Same source table, multiple filtered features\n",
    "2. **Performance**: Filtering happens during aggregation (optimized)\n",
    "3. **Maintainability**: Filter logic is part of feature definition\n",
    "4. **Clarity**: Feature name and filter are co-located\n",
    "\n",
    "#### Example Use Cases\n",
    "\n",
    "```python\n",
    "# Only count specific product activities\n",
    "filter_condition=\"jira_product = 'jsw'\"\n",
    "\n",
    "# Only aggregate high-value transactions\n",
    "filter_condition=\"amount > 100\"\n",
    "\n",
    "# Only include specific event types\n",
    "filter_condition=\"event_type = 'view'\"\n",
    "```\n",
    "\n",
    "#### Features We'll Create\n",
    "\n",
    "1. **jsw_activities_15d**: Activities specific to Jira Software (JSW)\n",
    "2. **bug_activities_30d**: Bug-related activities only\n",
    "\n",
    "These filtered features help identify product-specific or issue-type-specific engagement patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bd0a4ec-0cec-46d9-88db-d9095c59453e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature 16: JSW-specific activities (with filter_condition)\n",
    "jsw_activities_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"jsw_activities_30d\",\n",
    "    description=\"Count of Jira Software activities in last 30 days\",\n",
    "    source=jira_events_source,\n",
    "    inputs=[\"activity_type\"],\n",
    "    function=Count(),\n",
    "    filter_condition=\"jira_product = 'jsw'\",\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 17: Bug-related activities (with filter_condition)\n",
    "bug_activities_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"bug_activities_30d\",\n",
    "    description=\"Count of bug-related Jira activities in last 30 days\",\n",
    "    source=jira_events_source,\n",
    "    inputs=[\"activity_type\"],\n",
    "    function=Count(),\n",
    "    filter_condition=\"issue_type = 'bug'\",\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 18: Issue creation count (with filter_condition)\n",
    "issues_created_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"issues_resolved_30d\",\n",
    "    description=\"Count of Jira issues resolved in last 30 days\",\n",
    "    source=jira_events_source,\n",
    "    inputs=[\"issue_id\"],\n",
    "    function=ApproxCountDistinct(),\n",
    "    filter_condition=\"activity_type = 'resolve' \",\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Filtered Jira features created:\")\n",
    "print(\"  - jsw_activities_30d (filter: jira_product = 'jsw')\")\n",
    "print(\"  - bug_activities_30d (filter: issue_type = 'bug')\")\n",
    "print(\"  - issues_created_30d (filter: activity_type = 'create')\")\n",
    "print(\"  - issues_resolved_30d (filter: activity_type = 'resolve')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55fdce45-949b-410c-83f1-24f6af3f1712",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 16"
    }
   },
   "source": [
    "### 3.5 Statistical Features (StddevPop)\n",
    "\n",
    "#### Why Standard Deviation Matters for Churn Prediction\n",
    "\n",
    "`StddevPop()` (Population Standard Deviation) measures **consistency and variability** in user behavior:\n",
    "\n",
    "**High Standard Deviation** = Inconsistent behavior\n",
    "- Sporadic engagement\n",
    "- Unpredictable usage patterns\n",
    "- May indicate casual or declining users\n",
    "\n",
    "**Low Standard Deviation** = Consistent behavior\n",
    "- Regular engagement\n",
    "- Predictable usage patterns\n",
    "- Indicates habitual, committed users\n",
    "\n",
    "#### Features We'll Create\n",
    "\n",
    "1. **stddev_session_duration_30d**: Consistency of session lengths\n",
    "   - High variance: Erratic usage\n",
    "   - Low variance: Stable engagement\n",
    "\n",
    "2. **stddev_confluence_dwell_30d**: Consistency of Confluence engagement\n",
    "   - Measures collaboration pattern stability\n",
    "\n",
    "3. **stddev_jira_reactions_30d**: Consistency of Jira engagement\n",
    "   - Indicates project involvement stability\n",
    "\n",
    "#### Machine Learning Insight\n",
    "\n",
    "Standard deviation features often have high predictive power because:\n",
    "- They capture behavior patterns, not just volumes\n",
    "- Declining users often show increasing variance (erratic behavior)\n",
    "- Engaged users maintain consistent patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b577a03-afc5-4e80-872b-c64abb527537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature 20: Standard deviation of session duration (engagement consistency)\n",
    "stddev_duration_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"stddev_session_duration_30d\",\n",
    "    description=\"Standard deviation of session duration (engagement consistency)\",\n",
    "    source=click_events_source,\n",
    "    inputs=[\"duration_seconds\"],\n",
    "    function=StddevPop(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 21: Standard deviation of Confluence dwell time\n",
    "stddev_dwell_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"stddev_confluence_dwell_30d\",\n",
    "    description=\"Standard deviation of Confluence dwell time (reading consistency)\",\n",
    "    source=confluence_events_source,\n",
    "    inputs=[\"dwell_time_seconds\"],\n",
    "    function=StddevPop(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 22: Standard deviation of reactions (engagement variability)\n",
    "stddev_reactions_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"stddev_jira_reactions_30d\",\n",
    "    description=\"Standard deviation of Jira reaction counts (engagement variability)\",\n",
    "    source=jira_events_source,\n",
    "    inputs=[\"reaction_count\"],\n",
    "    function=StddevPop(),\n",
    "    time_window=SlidingWindow(\n",
    "        window_duration=timedelta(days=30),\n",
    "        slide_duration=timedelta(days=1)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Statistical features created (StddevPop):\")\n",
    "print(\"  - stddev_session_duration_30d\")\n",
    "print(\"  - stddev_confluence_dwell_30d\")\n",
    "print(\"  - stddev_jira_reactions_30d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3773e7b1-c89d-46d3-b204-7a7138d4e21d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 18"
    }
   },
   "source": [
    "### 3.6 Tenant-Level Features\n",
    "\n",
    "#### Multi-Entity Feature Engineering\n",
    "\n",
    "So far, all features have been at the **user level** (entity: `user_id`). Now we'll create features at the **tenant level** (entity: `tenant_id`).\n",
    "\n",
    "**Why Tenant-Level Features?**\n",
    "\n",
    "User churn is influenced by organizational health:\n",
    "- Users in struggling organizations are more likely to churn\n",
    "- Tenant-level metrics provide context for individual behavior\n",
    "- Combining user and tenant features improves prediction accuracy\n",
    "\n",
    "#### Features We'll Create\n",
    "\n",
    "1. **tenant_avg_key_events_30d**: Average daily key events for the organization\n",
    "   - Low values indicate declining organizational activity\n",
    "\n",
    "2. **tenant_max_active_users_30d**: Peak active user count\n",
    "   - Shows organizational engagement capacity\n",
    "\n",
    "3. **tenant_total_linked_aris_30d**: Total linked artifacts (integration usage)\n",
    "   - Indicates platform adoption depth\n",
    "\n",
    "#### Joining User and Tenant Features\n",
    "\n",
    "During training set creation, the Feature Engineering Client will:\n",
    "1. Compute user-level features for each user\n",
    "2. Compute tenant-level features for each tenant\n",
    "3. Join them based on the user-tenant relationship\n",
    "4. Ensure point-in-time correctness for both levels\n",
    "\n",
    "This multi-entity approach captures both individual and organizational signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "290ade7d-0e8e-4ce6-a435-1e894d49a031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature 23: Average tenant key events (organizational activity)\n",
    "tenant_avg_key_events_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"tenant_avg_key_events_30d\",\n",
    "    description=\"Average daily key events count for tenant over 30 days\",\n",
    "    source=tenant_metrics_source,\n",
    "    inputs=[\"key_events_count\"],\n",
    "    function=Avg(),\n",
    "    time_window=TumblingWindow(\n",
    "        window_duration=timedelta(days=30)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 24: Max active users (tenant health)\n",
    "tenant_max_active_users_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"tenant_max_active_users_30d\",\n",
    "    description=\"Maximum daily active users for tenant over 30 days\",\n",
    "    source=tenant_metrics_source,\n",
    "    inputs=[\"active_users_count\"],\n",
    "    function=Max(),\n",
    "    time_window=TumblingWindow(\n",
    "        window_duration=timedelta(days=30)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 25: Total linked ARIs (integration depth)\n",
    "tenant_total_aris_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"tenant_total_linked_aris_30d\",\n",
    "    description=\"Total linked ARIs for tenant over 30 days\",\n",
    "    source=tenant_metrics_source,\n",
    "    inputs=[\"linked_aris_count\"],\n",
    "    function=Sum(),\n",
    "    time_window=TumblingWindow(\n",
    "        window_duration=timedelta(days=30)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Feature 26: Average reporting lines (organization structure)\n",
    "tenant_avg_reporting_lines_30d = fe.create_feature(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    name=\"tenant_avg_reporting_lines_30d\",\n",
    "    description=\"Average reporting lines count for tenant over 30 days\",\n",
    "    source=tenant_metrics_source,\n",
    "    inputs=[\"reporting_lines_count\"],\n",
    "    function=Avg(),\n",
    "    time_window=TumblingWindow(\n",
    "        window_duration=timedelta(days=30)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Tenant-level features created:\")\n",
    "print(\"  - tenant_avg_key_events_30d\")\n",
    "print(\"  - tenant_max_active_users_30d\")\n",
    "print(\"  - tenant_total_linked_aris_30d\")\n",
    "print(\"  - tenant_avg_reporting_lines_30d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a8cc339-e2d0-4b2f-9bea-d2298de747b5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 20"
    }
   },
   "source": [
    "## 4. Collect All Features\n",
    "\n",
    "### Feature Organization\n",
    "\n",
    "Before materializing or using features, we organize them into logical groups:\n",
    "\n",
    "1. **User Engagement Features**: Click and session behavior\n",
    "2. **Confluence Collaboration Features**: Documentation and knowledge sharing\n",
    "3. **Jira Activity Features**: Project management and issue tracking\n",
    "4. **Statistical Features**: Variance and consistency metrics\n",
    "5. **Tenant-Level Features**: Organizational health indicators\n",
    "\n",
    "### Why Organize Features?\n",
    "\n",
    "- **Maintainability**: Easy to update or remove feature groups\n",
    "- **Materialization**: Can materialize different groups to different tables\n",
    "- **Experimentation**: Easy to test models with different feature combinations\n",
    "- **Documentation**: Clear feature lineage and purpose\n",
    "\n",
    "### Feature Naming Convention\n",
    "\n",
    "Our features follow a consistent naming pattern:\n",
    "- `{source}_{metric}_{window}` (e.g., `user_clicks_7d`)\n",
    "- `{source}_{aggregation}_{metric}_{window}` (e.g., `avg_session_duration_7d`)\n",
    "\n",
    "This makes features self-documenting and easy to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "609f9883-bb3a-4ac2-8361-01e305226f09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fe.list_features(full_name='ananyaroy.feature_store.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fa4cb6b-fe4f-4897-89dc-91dc43b93a8d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Organize features by type"
    }
   },
   "outputs": [],
   "source": [
    "# Organize features into separate lists by type\n",
    "\n",
    "# User Engagement Features (SlidingWindow)\n",
    "user_engagement_features = [\n",
    "    f\"{CATALOG}.{SCHEMA}.user_clicks_7d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.user_clicks_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.avg_session_duration_7d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.total_session_duration_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.unique_products_visited_30d\"\n",
    "]\n",
    "\n",
    "# Confluence Collaboration Features (SlidingWindow)\n",
    "confluence_features = [\n",
    "    f\"{CATALOG}.{SCHEMA}.confluence_dwell_time_14d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.confluence_avg_dwell_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.confluence_comments_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.confluence_unique_pages_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.confluence_events_7d_lagged\",\n",
    "    f\"{CATALOG}.{SCHEMA}.total_dwell_with_view_30d_lagged\"\n",
    "]\n",
    "\n",
    "# Jira Activity Features (TumblingWindow)\n",
    "jira_features = [\n",
    "    f\"{CATALOG}.{SCHEMA}.jira_activities_weekly\",\n",
    "    f\"{CATALOG}.{SCHEMA}.jira_max_reactions_weekly\",\n",
    "    f\"{CATALOG}.{SCHEMA}.jira_total_reactions_monthly\",\n",
    "    f\"{CATALOG}.{SCHEMA}.jira_unique_issues_monthly\",\n",
    "    f\"{CATALOG}.{SCHEMA}.jira_min_reactions_weekly\",\n",
    "    f\"{CATALOG}.{SCHEMA}.jsw_activities_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.bug_activities_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.issues_resolved_30d\"\n",
    "]\n",
    "\n",
    "# Statistical Features (StddevPop)\n",
    "statistical_features = [\n",
    "    f\"{CATALOG}.{SCHEMA}.stddev_session_duration_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.stddev_confluence_dwell_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.stddev_jira_reactions_30d\"\n",
    "]\n",
    "\n",
    "# Tenant-Level Features\n",
    "tenant_features = [\n",
    "    f\"{CATALOG}.{SCHEMA}.tenant_avg_key_events_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.tenant_max_active_users_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.tenant_total_linked_aris_30d\",\n",
    "    f\"{CATALOG}.{SCHEMA}.tenant_avg_reporting_lines_30d\"\n",
    "]\n",
    "\n",
    "# Print summary\n",
    "print(\"Feature Lists Created:\")\n",
    "print(f\"\\n1. User Engagement Features (SlidingWindow): {len(user_engagement_features)} features\")\n",
    "for f in user_engagement_features:\n",
    "    print(f\"   - {f.split('.')[-1]}\")\n",
    "\n",
    "print(f\"\\n2. Confluence Collaboration Features (SlidingWindow): {len(confluence_features)} features\")\n",
    "for f in confluence_features:\n",
    "    print(f\"   - {f.split('.')[-1]}\")\n",
    "\n",
    "print(f\"\\n3. Jira Activity Features : {len(jira_features)} features\")\n",
    "for f in jira_features:\n",
    "    print(f\"   - {f.split('.')[-1]}\")\n",
    "\n",
    "print(f\"\\n5. Statistical Features (StddevPop): {len(statistical_features)} features\")\n",
    "for f in statistical_features:\n",
    "    print(f\"   - {f.split('.')[-1]}\")\n",
    "\n",
    "print(f\"\\n6. Tenant-Level Features: {len(tenant_features)} features\")\n",
    "for f in tenant_features:\n",
    "    print(f\"   - {f.split('.')[-1]}\")\n",
    "\n",
    "print(f\"\\nTotal: {len(user_engagement_features) + len(confluence_features) + len(jira_features) + len(statistical_features) + len(tenant_features)} features organized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04a9c88b-246e-4fbf-8120-9d9d7b0bdbae",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 24"
    }
   },
   "source": [
    "## 5. Materialize Features\n",
    "\n",
    "### What is Feature Materialization?\n",
    "\n",
    "**Feature Materialization** is the process of pre-computing and storing features for reuse:\n",
    "\n",
    "#### Benefits\n",
    "\n",
    "1. **Performance**: Compute once, use many times\n",
    "2. **Consistency**: Same feature values across training and inference\n",
    "3. **Cost Efficiency**: Avoid recomputing expensive aggregations\n",
    "4. **Freshness**: Scheduled updates keep features current\n",
    "5. **Serving**: Enable low-latency online serving\n",
    "\n",
    "### Offline vs Online Stores\n",
    "\n",
    "| Offline Store | Online Store |\n",
    "|--------------|-------------|\n",
    "| Batch training and inference | Real-time serving |\n",
    "| Delta tables in Unity Catalog | Low-latency key-value store |\n",
    "| High throughput | Low latency (milliseconds) |\n",
    "| Historical data | Current data |\n",
    "\n",
    "### Materialization Configuration\n",
    "\n",
    "```python\n",
    "OfflineStoreConfig(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    table_name_prefix=\"feature_group_\"  # Creates tables with this prefix\n",
    ")\n",
    "```\n",
    "\n",
    "### Scheduling\n",
    "\n",
    "We'll use cron scheduling to keep features fresh:\n",
    "- `\"0 0 * * * ?\"` = Daily at midnight UTC\n",
    "- `pipeline_state=\"ACTIVE\"` = Enable automatic updates\n",
    "\n",
    "### What We'll Materialize\n",
    "\n",
    "We'll create separate materialized tables for each feature group:\n",
    "1. User engagement features  `user_engagement_*` tables\n",
    "2. Confluence features  `confluence_collaboration_*` tables\n",
    "3. Jira features  `jira_activity_*` tables\n",
    "4. Statistical features  `statistical_metrics_*` tables\n",
    "5. Tenant features  `tenant_level_*` tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef8b47eb-4961-42ea-956f-1d7d07368648",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Materialize User Engagement Features"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering.entities import OfflineStoreConfig\n",
    "\n",
    "# Get feature objects for user engagement features\n",
    "user_engagement_feature_objects = []\n",
    "for feature_name in [\"user_clicks_7d\", \"user_clicks_30d\", \"avg_session_duration_7d\", \n",
    "                     \"total_session_duration_30d\", \"unique_products_visited_30d\"]:\n",
    "    full_name = f\"{CATALOG}.{SCHEMA}.{feature_name}\"\n",
    "    try:\n",
    "        feature = fe.get_feature(full_name=full_name)\n",
    "        user_engagement_feature_objects.append(feature)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get {feature_name}: {e}\")\n",
    "\n",
    "# Configure offline store for user engagement features\n",
    "user_engagement_offline_store = OfflineStoreConfig(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    table_name_prefix=\"user_engagement\"\n",
    ")\n",
    "\n",
    "# Materialize user engagement features\n",
    "fe.materialize_features(\n",
    "    features=user_engagement_feature_objects,\n",
    "    offline_config=user_engagement_offline_store,\n",
    "    pipeline_state=\"ACTIVE\",\n",
    "    cron_schedule=\"0 0 * * * ?\"  # Daily at midnight\n",
    ")\n",
    "\n",
    "print(f\" Materialized {len(user_engagement_feature_objects)} user engagement features with prefix 'user_engagement'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59456fd7-ab31-4086-9876-c3fa2ad409d5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Materialize Confluence Features"
    }
   },
   "outputs": [],
   "source": [
    "# Get feature objects for confluence features\n",
    "confluence_feature_objects = []\n",
    "for feature_name in [\"confluence_dwell_time_14d\", \"confluence_avg_dwell_30d\", \"confluence_comments_30d\",\n",
    "                     \"confluence_unique_pages_30d\", \"confluence_events_7d_lagged\", \"total_dwell_with_view_30d_lagged\"]:\n",
    "    full_name = f\"{CATALOG}.{SCHEMA}.{feature_name}\"\n",
    "    try:\n",
    "        feature = fe.get_feature(full_name=full_name)\n",
    "        confluence_feature_objects.append(feature)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get {feature_name}: {e}\")\n",
    "\n",
    "# Configure offline store for confluence features\n",
    "confluence_offline_store = OfflineStoreConfig(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    table_name_prefix=\"confluence_collaboration\"\n",
    ")\n",
    "\n",
    "# Materialize confluence features\n",
    "fe.materialize_features(\n",
    "    features=confluence_feature_objects,\n",
    "    offline_config=confluence_offline_store,\n",
    "    pipeline_state=\"ACTIVE\",\n",
    "    cron_schedule=\"0 0 * * * ?\"  # Daily at midnight\n",
    ")\n",
    "\n",
    "print(f\" Materialized {len(confluence_feature_objects)} confluence features with prefix 'confluence_collaboration'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87160a4d-e203-422c-a0b9-ed6db5424f13",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Materialize Jira Features"
    }
   },
   "outputs": [],
   "source": [
    "# Get feature objects for jira features\n",
    "jira_feature_objects = []\n",
    "for feature_name in [\"jira_activities_weekly\", \"jira_max_reactions_weekly\", \"jira_total_reactions_monthly\",\n",
    "                     \"jira_unique_issues_monthly\", \"jira_min_reactions_weekly\", \"jsw_activities_30d\",\n",
    "                     \"bug_activities_30d\", \"issues_resolved_30d\"]:\n",
    "    full_name = f\"{CATALOG}.{SCHEMA}.{feature_name}\"\n",
    "    try:\n",
    "        feature = fe.get_feature(full_name=full_name)\n",
    "        jira_feature_objects.append(feature)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get {feature_name}: {e}\")\n",
    "\n",
    "# Configure offline store for jira features\n",
    "jira_offline_store = OfflineStoreConfig(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    table_name_prefix=\"jira_activity\"\n",
    ")\n",
    "\n",
    "# Materialize jira features\n",
    "fe.materialize_features(\n",
    "    features=jira_feature_objects,\n",
    "    offline_config=jira_offline_store,\n",
    "    pipeline_state=\"ACTIVE\",\n",
    "    cron_schedule=\"0 0 * * * ?\"  # Daily at midnight\n",
    ")\n",
    "\n",
    "print(f\" Materialized {len(jira_feature_objects)} jira features with prefix 'jira_activity'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ebc2351-2ce9-4c6b-9829-5ac1f81b9dc0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Materialize Statistical Features"
    }
   },
   "outputs": [],
   "source": [
    "# Get feature objects for statistical features\n",
    "statistical_feature_objects = []\n",
    "for feature_name in [\"stddev_session_duration_30d\", \"stddev_confluence_dwell_30d\", \"stddev_jira_reactions_30d\"]:\n",
    "    full_name = f\"{CATALOG}.{SCHEMA}.{feature_name}\"\n",
    "    try:\n",
    "        feature = fe.get_feature(full_name=full_name)\n",
    "        statistical_feature_objects.append(feature)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get {feature_name}: {e}\")\n",
    "\n",
    "# Configure offline store for statistical features\n",
    "statistical_offline_store = OfflineStoreConfig(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    table_name_prefix=\"statistical_metrics\"\n",
    ")\n",
    "\n",
    "# Materialize statistical features\n",
    "fe.materialize_features(\n",
    "    features=statistical_feature_objects,\n",
    "    offline_config=statistical_offline_store,\n",
    "    pipeline_state=\"ACTIVE\",\n",
    "    cron_schedule=\"0 0 * * * ?\"  # Daily at midnight\n",
    ")\n",
    "\n",
    "print(f\" Materialized {len(statistical_feature_objects)} statistical features with prefix 'statistical_metrics'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cd173f4-179c-4fda-b88c-43f4b16cfe56",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Materialize Tenant Features"
    }
   },
   "outputs": [],
   "source": [
    "# Get feature objects for tenant features\n",
    "tenant_feature_objects = []\n",
    "for feature_name in [\"tenant_avg_key_events_30d\", \"tenant_max_active_users_30d\", \n",
    "                     \"tenant_total_linked_aris_30d\", \"tenant_avg_reporting_lines_30d\"]:\n",
    "    full_name = f\"{CATALOG}.{SCHEMA}.{feature_name}\"\n",
    "    try:\n",
    "        feature = fe.get_feature(full_name=full_name)\n",
    "        tenant_feature_objects.append(feature)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get {feature_name}: {e}\")\n",
    "\n",
    "# Configure offline store for tenant features\n",
    "tenant_offline_store = OfflineStoreConfig(\n",
    "    catalog_name=CATALOG,\n",
    "    schema_name=SCHEMA,\n",
    "    table_name_prefix=\"tenant_level\"\n",
    ")\n",
    "\n",
    "# Materialize tenant features\n",
    "fe.materialize_features(\n",
    "    features=tenant_feature_objects,\n",
    "    offline_config=tenant_offline_store,\n",
    "    pipeline_state=\"ACTIVE\",\n",
    "    cron_schedule=\"0 0 * * * ?\"  # Daily at midnight\n",
    ")\n",
    "\n",
    "print(f\" Materialized {len(tenant_feature_objects)} tenant features with prefix 'tenant_level'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0c29ce9-f3ae-4e27-8c43-d6e9a4fca80e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Summary of Materialized Features"
    }
   },
   "outputs": [],
   "source": [
    "# Summary of all materialized feature tables\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE MATERIALIZATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAll features materialized to: {CATALOG}.{SCHEMA}\")\n",
    "print(\"\\nTable Prefixes Created:\")\n",
    "print(f\"  1. user_engagement_* ({len(user_engagement_feature_objects)} features)\")\n",
    "print(f\"  2. confluence_collaboration_* ({len(confluence_feature_objects)} features)\")\n",
    "print(f\"  3. jira_activity_* ({len(jira_feature_objects)} features)\")\n",
    "print(f\"  4. statistical_metrics_* ({len(statistical_feature_objects)} features)\")\n",
    "print(f\"  5. tenant_level_* ({len(tenant_feature_objects)} features)\")\n",
    "print(f\"\\nTotal Features Materialized: {len(user_engagement_feature_objects) + len(confluence_feature_objects) + len(jira_feature_objects) + len(statistical_feature_objects) + len(tenant_feature_objects)}\")\n",
    "print(f\"\\nSchedule: Daily at midnight (0 0 * * * ?)\")\n",
    "print(f\"Pipeline State: ACTIVE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a1da506-0b83-4817-990a-354dbe3a64e4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 31"
    }
   },
   "source": [
    "## 6. Prepare Training Data with Labels\n",
    "\n",
    "### Understanding Training Labels\n",
    "\n",
    "For supervised learning, we need labeled data:\n",
    "- **Label**: `churned` (1 = churned, 0 = retained)\n",
    "- **Event Time**: `event_ts` - the point in time when we make the prediction\n",
    "- **Entity Keys**: `user_id` and `tenant_id` to join with features\n",
    "\n",
    "### Point-in-Time Correctness\n",
    "\n",
    "The `event_ts` is critical for preventing **data leakage**:\n",
    "\n",
    "**Without Point-in-Time Correctness**  \n",
    "- Features might include data from AFTER the prediction time\n",
    "- Model learns from \"future\" information\n",
    "- Unrealistic performance in training, poor performance in production\n",
    "\n",
    "**With Point-in-Time Correctness**  \n",
    "- Features only use data available BEFORE event_ts\n",
    "- Realistic training conditions\n",
    "- Production performance matches training performance\n",
    "\n",
    "### Example\n",
    "\n",
    "If `event_ts = 2024-01-15`:\n",
    "- `user_clicks_7d` will count clicks from 2024-01-08 to 2024-01-15\n",
    "- `user_clicks_30d` will count clicks from 2023-12-16 to 2024-01-15\n",
    "- No data after 2024-01-15 will be included\n",
    "\n",
    "The Feature Engineering Client handles this automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c36b9ce0-4662-41d3-8671-9ac5d8a57c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load churn labels with user and tenant info\n",
    "labels_df = spark.table(f\"{CATALOG}.{SOURCE_SCHEMA}.churn_labels\")\n",
    "\n",
    "# Rename label_ts to be used as point-in-time reference\n",
    "labels_df = labels_df.withColumnRenamed(\"label_ts\", \"event_ts\")\n",
    "\n",
    "print(f\"Labels loaded: {labels_df.count()} records\")\n",
    "print(f\"Churn rate: {labels_df.filter(F.col('churned') == 1).count() / labels_df.count():.2%}\")\n",
    "labels_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "365702e1-f114-4fb8-af6e-8a29027eebe5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 33"
    }
   },
   "source": [
    "## 7. Create Training Set with Point-in-Time Correctness\n",
    "\n",
    "### The create_training_set() API\n",
    "\n",
    "This is where the magic happens! `create_training_set()` automatically:\n",
    "\n",
    "1. **Identifies Entity Keys**: Matches `user_id` and `tenant_id` from labels to features\n",
    "2. **Performs Point-in-Time Joins**: Uses `event_ts` to compute features correctly\n",
    "3. **Handles Multiple Entities**: Joins both user-level and tenant-level features\n",
    "4. **Computes Aggregations**: Calculates all window-based features on-the-fly\n",
    "5. **Returns Training DataFrame**: Ready-to-use data for model training\n",
    "\n",
    "### API Parameters\n",
    "\n",
    "```python\n",
    "fe.create_training_set(\n",
    "    df=labels_df,                    # Labels with event_ts\n",
    "    features=feature_objects,        # List of Feature objects\n",
    "    label=\"churned\",                 # Target column name\n",
    "    exclude_columns=[\"user_id\", \"event_ts\"]  # Columns to exclude from features\n",
    ")\n",
    "```\n",
    "\n",
    "### What Happens Behind the Scenes\n",
    "\n",
    "For each row in `labels_df`:\n",
    "1. Extract `user_id`, `tenant_id`, and `event_ts`\n",
    "2. For each feature:\n",
    "   - Find the source table\n",
    "   - Filter to the entity (user or tenant)\n",
    "   - Apply the time window relative to `event_ts`\n",
    "   - Compute the aggregation\n",
    "3. Join all features together\n",
    "4. Return complete training dataset\n",
    "\n",
    "### No Manual Joins Required!\n",
    "\n",
    "Traditionally, you'd write complex Spark SQL with:\n",
    "- Multiple window functions\n",
    "- Careful timestamp filtering\n",
    "- Manual joins across tables\n",
    "\n",
    "The declarative API handles all of this automatically and correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4d21a8c-08b1-4f68-acb3-2cd16d1e949b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770202614100}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "labels_df = labels_df.withColumnRenamed('observation_ts' , 'event_ts')\n",
    "display(labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc70ea0a-f4f4-4cd1-a8c7-6e8795d4463a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create training set with user-level features\n",
    "# The API automatically handles point-in-time joins based on event_ts\n",
    "\n",
    "# Convert feature names to Feature objects\n",
    "\n",
    "user_training_set = fe.create_training_set(\n",
    "    df=labels_df,\n",
    "    features=user_engagement_feature_objects + confluence_feature_objects + jira_feature_objects + statistical_feature_objects  ,\n",
    "    label=\"churned\",\n",
    "    exclude_columns=[\"user_id\",\"event_ts\",\"tenant_id\"]  # Exclude timestamp from features\n",
    ")\n",
    "\n",
    "# Load the training DataFrame\n",
    "user_training_df = user_training_set.load_df()\n",
    "\n",
    "print(f\"User training set created with {len(user_training_df.columns)} columns\")\n",
    "print(f\"Columns: {user_training_df.columns}\")\n",
    "display(user_training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cb55f86-d978-46b1-80ee-8978e14817e2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 36"
    }
   },
   "source": [
    "## 8. Train Churn Prediction Model\n",
    "\n",
    "### Model Training Workflow\n",
    "\n",
    "Now that we have our training set with all features, we'll:\n",
    "\n",
    "1. **Convert to Pandas**: sklearn works with Pandas DataFrames\n",
    "2. **Prepare Features**: Select feature columns, handle missing values\n",
    "3. **Train-Test Split**: Stratified split to maintain class balance\n",
    "4. **Train Model**: Gradient Boosting Classifier\n",
    "5. **Evaluate**: Classification metrics and feature importance\n",
    "6. **Log with MLflow**: Track experiment with feature lineage\n",
    "\n",
    "### Why Gradient Boosting?\n",
    "\n",
    "- **Handles Mixed Features**: Works well with count, average, and variance features\n",
    "- **Feature Importance**: Provides interpretable feature rankings\n",
    "- **Robust to Missing Data**: Can handle nulls in features\n",
    "- **Good Performance**: Strong baseline for tabular data\n",
    "\n",
    "### Feature Importance Analysis\n",
    "\n",
    "After training, we'll examine which features are most predictive:\n",
    "- Helps validate feature engineering choices\n",
    "- Identifies key churn signals\n",
    "- Guides future feature development\n",
    "\n",
    "### MLflow Integration\n",
    "\n",
    "We'll log:\n",
    "- Model parameters and metrics\n",
    "- Feature metadata (counts by category)\n",
    "- Feature names as JSON artifact\n",
    "- Model with feature lineage (next section)\n",
    "\n",
    "This creates a complete audit trail from raw data to predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c90f6f6-903b-488b-a02a-01ed29c02e43",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 38"
    }
   },
   "source": [
    "## 9. Log Model with Feature Lineage\n",
    "\n",
    "### What is Feature Lineage?\n",
    "\n",
    "**Feature Lineage** tracks the complete data flow from source tables to model predictions:\n",
    "\n",
    "```\n",
    "Source Tables  Features  Training Set  Model  Predictions\n",
    "```\n",
    "\n",
    "### Why Feature Lineage Matters\n",
    "\n",
    "1. **Reproducibility**: Know exactly which data created which model\n",
    "2. **Debugging**: Trace prediction issues back to source data\n",
    "3. **Compliance**: Audit trail for regulated industries\n",
    "4. **Impact Analysis**: Understand downstream effects of data changes\n",
    "5. **Automatic Feature Computation**: Model knows how to compute its features\n",
    "\n",
    "### The log_model() API\n",
    "\n",
    "```python\n",
    "fe.log_model(\n",
    "    model=model,                     # Trained sklearn model\n",
    "    artifact_path=\"churn_model\",     # Path in MLflow\n",
    "    flavor=mlflow.sklearn,           # Model flavor\n",
    "    training_set=user_training_set,  # Links to feature definitions\n",
    "    registered_model_name=\"...\"      # Register in Unity Catalog\n",
    ")\n",
    "```\n",
    "\n",
    "### What Gets Stored\n",
    "\n",
    "1. **Model Artifact**: The trained model itself\n",
    "2. **Feature Metadata**: Names, sources, aggregations, windows\n",
    "3. **Source Table References**: Which tables contain the raw data\n",
    "4. **Computation Logic**: How to compute features from sources\n",
    "5. **Entity Keys**: How to join features\n",
    "\n",
    "### Benefits for Inference\n",
    "\n",
    "When you load this model for inference:\n",
    "- Provide just the entity keys (`user_id`, `tenant_id`) and timestamp\n",
    "- Model automatically computes all required features\n",
    "- No need to manually replicate feature engineering logic\n",
    "- Guaranteed consistency between training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12c2a354-9a89-4f3a-ba5d-384ab3c3f4cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "with mlflow.start_run(run_name=\"fs_churn_prediction\") as run :\n",
    "\n",
    "    # Convert to Pandas for sklearn training\n",
    "    training_pdf = user_training_df.toPandas()\n",
    "\n",
    "    # Prepare features and labels\n",
    "    feature_columns = [col for col in training_pdf.columns if col not in [\"user_id\", \"tenant_id\", \"churned\"]]\n",
    "    X = training_pdf[feature_columns].fillna(0)\n",
    "    y = training_pdf[\"churned\"]\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    print(f\"Training set: {len(X_train)} samples\")\n",
    "    print(f\"Test set: {len(X_test)} samples\")\n",
    "    print(f\"Feature count: {len(feature_columns)}\")\n",
    "\n",
    "    # Train Gradient Boosting Classifier\n",
    "    model = Pipeline([('imputer',SimpleImputer(strategy=\"median\")),('classifier',GradientBoostingClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42))]\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Model Training Complete\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        \"feature\": feature_columns,\n",
    "        \"importance\": model.named_steps['classifier'].feature_importances_\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    print(\"Top 15 Most Important Features for Churn Prediction:\")\n",
    "    display(feature_importance.head(15))\n",
    "\n",
    "    # Log feature metadata\n",
    "    all_feature_objects = (\n",
    "                        user_engagement_feature_objects + \n",
    "                        confluence_feature_objects + \n",
    "                        jira_feature_objects + \n",
    "                        statistical_feature_objects)\n",
    "\n",
    "    # Log feature counts by category\n",
    "    mlflow.log_param(\"num_user_engagement_features\", len(user_engagement_feature_objects))\n",
    "    mlflow.log_param(\"num_confluence_features\", len(confluence_feature_objects))\n",
    "    mlflow.log_param(\"num_jira_features\", len(jira_feature_objects))\n",
    "    mlflow.log_param(\"num_statistical_features\", len(statistical_feature_objects))\n",
    "    mlflow.log_param(\"total_features\", len(all_feature_objects))\n",
    "\n",
    "    # Log feature names as a JSON artifact\n",
    "    import json\n",
    "    feature_metadata = {\n",
    "        \"user_engagement_features\": [f.name for f in user_engagement_feature_objects],\n",
    "        \"confluence_features\": [f.name for f in confluence_feature_objects],\n",
    "        \"jira_features\": [f.name for f in jira_feature_objects],\n",
    "        \"statistical_features\": [f.name for f in statistical_feature_objects]\n",
    "    }\n",
    "\n",
    "    with open(\"/tmp/feature_metadata.json\", \"w\") as f:\n",
    "        json.dump(feature_metadata, f, indent=2)\n",
    "    mlflow.log_artifact(\"/tmp/feature_metadata.json\")\n",
    "\n",
    "    # Log model with feature engineering lineage\n",
    "    fe.log_model(\n",
    "        model=model,\n",
    "        artifact_path=\"churn_model\",\n",
    "        flavor=mlflow.sklearn,\n",
    "        training_set=user_training_set,\n",
    "        registered_model_name=f\"{CATALOG}.{SCHEMA}.fs_churn_prediction_model\"\n",
    "    )\n",
    "\n",
    "    print(f\" Model logged with feature lineage\")\n",
    "    print(f\" Registered model: {CATALOG}.{SCHEMA}.churn_prediction_model\")\n",
    "    print(f\" Total features logged: {len(all_feature_objects)}\")\n",
    "    print(f\"\\nFeature breakdown:\")\n",
    "    print(f\"  - User Engagement: {len(user_engagement_feature_objects)}\")\n",
    "    print(f\"  - Confluence: {len(confluence_feature_objects)}\")\n",
    "    print(f\"  - Jira: {len(jira_feature_objects)}\")\n",
    "    print(f\"  - Statistical: {len(statistical_feature_objects)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6359eab-681a-4a8b-a528-d715b14814a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 40"
    }
   },
   "source": [
    "## 10. Batch Scoring with score_batch()\n",
    "\n",
    "### Simplified Inference\n",
    "\n",
    "The `score_batch()` API makes inference incredibly simple:\n",
    "\n",
    "**Traditional Approach** \n",
    "1. Load source tables\n",
    "2. Manually compute all features\n",
    "3. Join features together\n",
    "4. Load model\n",
    "5. Make predictions\n",
    "6. Hope feature logic matches training\n",
    "\n",
    "**With score_batch()** \n",
    "1. Provide entity keys and timestamp\n",
    "2. Call `score_batch()`\n",
    "3. Get predictions\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```python\n",
    "fe.score_batch(\n",
    "    model_uri=\"models:/catalog.schema.model_name/version\",\n",
    "    df=inference_df  # Just needs: user_id, tenant_id, event_ts\n",
    ")\n",
    "```\n",
    "\n",
    "The API:\n",
    "1. Loads the model and its feature lineage\n",
    "2. Identifies required features\n",
    "3. Computes features from source tables (point-in-time correct)\n",
    "4. Applies the model\n",
    "5. Returns predictions with all features\n",
    "\n",
    "### Point-in-Time Correctness in Inference\n",
    "\n",
    "Just like training, inference respects the timestamp:\n",
    "- If `event_ts = 2024-02-06`, features only use data up to that date\n",
    "- Enables backtesting and historical analysis\n",
    "- For real-time scoring, use `current_timestamp()`\n",
    "\n",
    "### What You Get Back\n",
    "\n",
    "The result DataFrame includes:\n",
    "- Original columns (`user_id`, `tenant_id`, `event_ts`)\n",
    "- All computed features\n",
    "- Model predictions\n",
    "\n",
    "This transparency helps with debugging and model monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "677e4e70-22ba-4fc0-80e3-02ce6206e3da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare inference data (new users to score)\n",
    "inference_df = spark.table(f\"{CATALOG}.{SOURCE_SCHEMA}.user_tenant_mapping\").limit(100)\n",
    "inference_df = inference_df.withColumn(\"event_ts\", F.current_timestamp())\n",
    "\n",
    "print(f\"Inference data: {inference_df.count()} users to score\")\n",
    "inference_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "466c8ee2-cddb-46fd-8060-7e890b17d0fa",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770209591196}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Score batch with automatic point-in-time feature computation\n",
    "predictions_df = fe.score_batch(\n",
    "    model_uri=f\"models:/{CATALOG}.{SCHEMA}.fs_churn_prediction_model/2\",\n",
    "    df=inference_df\n",
    ")\n",
    "display(predictions_df)\n",
    "# print(\"Batch scoring complete\")\n",
    "# print(f\"Predictions: {predictions_df.count()} rows\")\n",
    "# predictions_df.select(\"user_id\", \"tenant_id\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "144d755b-16a9-4241-978f-8bd058c088db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display( predictions_df.groupBy(\"prediction\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2e11bd2-9e67-4dce-aee0-ef24211f4562",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 47"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "This notebook demonstrated a **complete end-to-end feature engineering and ML workflow** using Databricks declarative APIs:\n",
    "\n",
    "1.  Defined data sources with entity and timeseries columns\n",
    "2.  Created 26 features using multiple aggregation functions and window types\n",
    "3.  Materialized features to offline stores with scheduling\n",
    "4.  Generated point-in-time correct training data\n",
    "5.  Trained a churn prediction model\n",
    "6.  Logged model with complete feature lineage\n",
    "7.  Performed batch inference with automatic feature computation\n",
    "\n",
    "---\n",
    "\n",
    "### APIs Reference\n",
    "\n",
    "| API | Purpose | Key Parameters |\n",
    "|-----|---------|---------------|\n",
    "| `FeatureEngineeringClient()` | Initialize client | None |\n",
    "| `DeltaTableSource()` | Define source | `catalog_name`, `schema_name`, `table_name`, `entity_columns`, `timeseries_column` |\n",
    "| `create_feature()` | Create feature | `name`, `source`, `inputs`, `function`, `time_window`, `filter_condition` |\n",
    "| `create_training_set()` | Generate training data | `df`, `features`, `label`, `exclude_columns` |\n",
    "| `materialize_features()` | Store features | `features`, `offline_config`, `online_config`, `pipeline_state`, `cron_schedule` |\n",
    "| `log_model()` | Log with lineage | `model`, `artifact_path`, `flavor`, `training_set`, `registered_model_name` |\n",
    "| `score_batch()` | Batch inference | `model_uri`, `df` |\n",
    "\n",
    "---\n",
    "\n",
    "### Aggregation Functions\n",
    "\n",
    "| Function | Use Case | Example |\n",
    "|----------|----------|--------|\n",
    "| `Count()` | Event frequency | Total clicks, activities |\n",
    "| `Sum()` | Cumulative values | Total duration, reactions |\n",
    "| `Avg()` | Central tendency | Average session length |\n",
    "| `Min()` / `Max()` | Range analysis | Peak/minimum engagement |\n",
    "| `StddevPop()` | Consistency | Behavior variance |\n",
    "| `ApproxCountDistinct()` | Cardinality | Unique products, pages |\n",
    "\n",
    "---\n",
    "\n",
    "### Time Window Types\n",
    "\n",
    "#### SlidingWindow\n",
    "- **Pattern**: Overlapping rolling windows\n",
    "- **Use Case**: Trend analysis, smooth metrics\n",
    "- **Example**: \"Clicks in last 7 days\" (slides daily)\n",
    "- **Parameters**: `window_duration`, `slide_duration`\n",
    "\n",
    "#### TumblingWindow\n",
    "- **Pattern**: Non-overlapping fixed windows\n",
    "- **Use Case**: Periodic reports, discrete buckets\n",
    "- **Example**: \"Weekly activity count\"\n",
    "- **Parameters**: `window_duration`\n",
    "\n",
    "#### ContinuousWindow\n",
    "- **Pattern**: Lookback from event time\n",
    "- **Use Case**: Point-in-time aggregations with offset\n",
    "- **Example**: \"Events in last 30 days with 1-day lag\"\n",
    "- **Parameters**: `window_duration`, `offset`\n",
    "\n",
    "---\n",
    "\n",
    "### Features Created\n",
    "\n",
    "**User Engagement (5 features)**\n",
    "- Click counts (7d, 30d)\n",
    "- Session duration (avg 7d, total 30d)\n",
    "- Product diversity (30d)\n",
    "\n",
    "**Confluence Collaboration (6 features)**\n",
    "- Dwell time (14d, avg 30d)\n",
    "- Comments (30d)\n",
    "- Unique pages (30d)\n",
    "- Lagged metrics (7d, 30d)\n",
    "\n",
    "**Jira Activity (5 features)**\n",
    "- Weekly activities\n",
    "- Reaction statistics (max, min, total)\n",
    "- Unique issues (monthly)\n",
    "\n",
    "**Filtered Features (2 features)**\n",
    "- JSW-specific activities\n",
    "- Bug-related activities\n",
    "\n",
    "**Statistical Features (3 features)**\n",
    "- Session duration variance\n",
    "- Confluence dwell variance\n",
    "- Jira reaction variance\n",
    "\n",
    "**Tenant-Level Features (3 features)**\n",
    "- Average key events\n",
    "- Max active users\n",
    "- Total linked artifacts\n",
    "\n",
    "**Total: 24 features** across multiple entities and time windows\n",
    "\n",
    "---\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "1. **Use Descriptive Names**: `user_clicks_7d` is better than `feature_1`\n",
    "2. **Organize by Category**: Group related features for maintainability\n",
    "3. **Choose Appropriate Windows**: Match window type to use case\n",
    "4. **Leverage Filter Conditions**: Create focused features without pre-filtering\n",
    "5. **Include Statistical Features**: Variance often has high predictive power\n",
    "6. **Multi-Entity Features**: Combine user and organizational signals\n",
    "7. **Point-in-Time Correctness**: Always use observation timestamps\n",
    "8. **Feature Lineage**: Log models with training sets for reproducibility\n",
    "9. **Materialize Strategically**: Balance freshness, cost, and latency\n",
    "10. **Monitor Feature Quality**: Track feature distributions over time\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Experiment with Features**: Try different window sizes and aggregations\n",
    "2. **Add More Sources**: Incorporate additional data sources\n",
    "3. **Feature Selection**: Use feature importance to prune low-value features\n",
    "4. **Online Serving**: Deploy model with online feature store\n",
    "5. **Monitoring**: Set up feature drift detection\n",
    "6. **A/B Testing**: Compare models with different feature sets\n",
    "\n",
    "---\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [Databricks Feature Engineering Documentation](https://docs.databricks.com/machine-learning/feature-store/index.html)\n",
    "- [Unity Catalog Feature Engineering](https://docs.databricks.com/en/machine-learning/feature-store/uc/feature-tables-uc.html)\n",
    "- [MLflow Model Registry](https://docs.databricks.com/mlflow/model-registry.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "669c1e32-0bd0-4578-b850-26e08dbaae8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01_churn_prediction_feature_pipeline",
   "widgets": {
    "catalog": {
     "currentValue": "ananyaroy",
     "nuid": "06082d4d-12ff-477f-b02d-1951d2be8c9c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ananyaroy",
      "label": "Catalog Name",
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "ananyaroy",
      "label": "Catalog Name",
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "fs_demo",
     "nuid": "a7cfd1ee-d142-4cf8-8450-6725199e75c6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "feature_store",
      "label": "Schema Name",
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "feature_store",
      "label": "Schema Name",
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "source_schema": {
     "currentValue": "feature_store",
     "nuid": "ef0846a2-7864-4158-b9a2-da43dbfd9a18",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "source schema",
      "name": "source_schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "source schema",
      "name": "source_schema",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
